import json
import os
import logging
import sys
import glob

# Configuration
DATA_DIR = "report_data"
LIBRARY_FILE = "market-reports-library.json"

# Configure logging to stdout for automation capture
logging.basicConfig(level=logging.INFO, format='BUILDER: %(message)s', handlers=[logging.StreamHandler(sys.stdout)])

def find_index_files(directory):
    """Dynamically finds all index files (e.g., mombasa_index.json) in the data directory."""
    if not os.path.exists(directory):
        logging.warning(f"Data directory not found: {directory}. No indexes to process.")
        return []
    # Use glob to find all files matching the pattern *_index.json
    return glob.glob(os.path.join(directory, "*_index.json"))

def transform_to_library_format(item, source_name="TeaTrade Analytics"):
    """Transforms a single analysis index entry to the front-end library format."""
    try:
        location = item.get('location', 'Unknown')
        year = item.get('year', 'Unknown')
        
        # We rely on 'sale_num_only' generated by the analysis scripts
        week_num = item.get('sale_num_only')

        # Construct Title
        title = f"{location} Auction Analysis"

        # Construct Link
        # For now, we link directly to the raw JSON data file.
        # If you create a viewer page (e.g., report_viewer.html?data=...), update this link later.
        link = os.path.join(DATA_DIR, item['filename'])

        # Structure required by market-reports.html
        library_entry = {
            "year": year,
            "week_number": week_num,
            "title": title,
            "description": item.get('snapshot', 'Awaiting data.'),
            "auction_centre": location,
            "source": source_name,
            "report_link": link
        }
        return library_entry
    except KeyError as e:
        logging.error(f"Skipping item due to missing key {e}: {item}")
        return None

def main():
    logging.info("Starting Library Consolidation Process...")
    index_files = find_index_files(DATA_DIR)
    all_library_data = []

    if not index_files:
        logging.info("No index files found.")
    else:
        for filepath in index_files:
            logging.info(f"Processing: {filepath}")
            try:
                with open(filepath, 'r') as f:
                    index_data = json.load(f)
                
                for item in index_data:
                    transformed_item = transform_to_library_format(item)
                    if transformed_item:
                        all_library_data.append(transformed_item)

            except Exception as e:
                logging.error(f"Error processing file {filepath}: {e}")

    # Sort the final list (Newest first based on year and week number)
    def sort_key(item):
        # Handle potential non-numeric years or weeks safely (placing them last)
        year = int(item.get('year')) if str(item.get('year')).isdigit() else 0
        
        # Ensure week_number is handled correctly even if it's an int (like sale_num_only)
        week_str = str(item.get('week_number'))
        week = int(week_str) if week_str.isdigit() else 0
        
        return (year, week)

    all_library_data.sort(key=sort_key, reverse=True)

    # Save the final library file
    try:
        with open(LIBRARY_FILE, 'w') as f:
            json.dump(all_library_data, f, indent=2)
        logging.info(f"Successfully generated {LIBRARY_FILE} with {len(all_library_data)} entries.")
    except Exception as e:
        logging.error(f"Error saving library file: {e}")

if __name__ == "__main__":
    main()